# Risk-Tolerance-Analysis

Install the dependencies and RUN THE **CREW.PY** to see the workflow

In the **agents.py** file set **verbose=True** for all agents to see communication between agents in command shell

In the **demo.txt** file an example is shown of agents communication during the development phase

A new file would be created during execution of crew.py named as "**crew_execution.log**", it will store the logging results 

**For this project I've used "llama-3.1-70b-versatile" model as LLM, Crew AI for communication between agents, google-generativeai for embedding.
For model inferencing I've used Groq API.
Complete project has been made using free open source tools.**
